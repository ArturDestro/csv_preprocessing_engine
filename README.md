# CSV Preprocessing Engine

A modular, config-driven preprocessing engine for CSV datasets, designed for reproducible and scalable machine learning pipelines.

---

## ğŸš€ Overview

This project provides a **lightweight preprocessing framework** for tabular data stored in CSV files.  
Instead of writing ad-hoc pandas scripts, you define a **configuration-driven pipeline** that transforms raw CSV data into **ML-ready datasets**.

The engine follows clear responsibilities and explicit transformation steps, inspired by production-grade ML pipelines.

---

## âœ¨ Key Features

- ğŸ“„ CSV in â†’ CSV out (no API or frontend required)
- âš™ï¸ Fully **config-driven** preprocessing
- ğŸ§© Modular architecture (Loader, Cleaner, Encoder, Scaler)
- ğŸ” Reproducible transformations (`fit` / `transform`)
- ğŸ§ª Easy to test and extend
- ğŸ§  Designed for ML and data science workflows

---

## ğŸ§± Architecture

The engine is composed of independent modules, each with a **single responsibility**:

```text
engine/
â”œâ”€â”€ Cleaner/
â”‚   â”œâ”€â”€ cleaner.py              # Base cleaner interface
â”‚   â”œâ”€â”€ cleaner_static.py       # Stateless cleaning utilities
â”‚   â””â”€â”€ cleanerFactory.py       # Cleaner factory
â”‚
â”œâ”€â”€ Encoder/
â”‚   â”œâ”€â”€ encoder.py              # Base encoder interface
â”‚   â””â”€â”€ encoderFactory.py       # Encoder factory
â”‚
â”œâ”€â”€ Loader/
â”‚   â”œâ”€â”€ csv_loader.py           # CSV loader implementation
â”‚   â””â”€â”€ loaderFactory.py        # Loader factory
â”‚
â”œâ”€â”€ Scaler/
â”‚   â”œâ”€â”€ scaler.py               # Base scaler interface
â”‚   â””â”€â”€ scalerFactory.py        # Scaler factory
â”‚
â”œâ”€â”€ pipeline.py                 # Pipeline orchestration
â”œâ”€â”€ test.py                     # Local tests / experiments
```
Each component respects the following principles:

No hidden decisions

No dataset-specific logic

Behavior is defined only by configuration

ğŸ”„ Processing Flow
```text
CSV
 â†“
Loader      â†’ reads raw data
 â†“
Cleaner     â†’ handles missing values
 â†“
Encoder     â†’ encodes categorical columns
 â†“
Scaler      â†’ scales numerical features
 â†“
Processed CSV (ML-ready)
```

âš™ï¸ Configuration Example
```text
config = {
    "loader": {
        "path": "data/raw.csv",
        "separator": ",",
        "encoding": "utf-8"
    },
    "cleaner": {
        "type": "mean",
        "columns": ["age", "salary"]
    },
    "encoder": {
        "type": "onehot",
        "columns": ["city", "gender"]
    },
    "scaler": {
        "type": "standard",
        "columns": ["age", "salary"]
    }
}
```

ğŸ§ª Example Usage
```text
from pipeline import Pipeline

pipeline = Pipeline(config)
df_processed = pipeline.run()
```
